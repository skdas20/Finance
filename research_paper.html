<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Robust Generalization in Autonomous Trading Agents</title>
    <!-- MathJax for LaTeX Equations -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true
            }
        };
    </script>
    <style>
        body {
            font-family: "Times New Roman", Times, serif;
            line-height: 1.6;
            margin: 0;
            padding: 40px;
            color: #000;
            max-width: 8.5in;
            margin: 0 auto;
            background-color: #fff;
            counter-reset: section;
        }
        h1 {
            font-size: 24pt;
            text-align: center;
            font-weight: normal;
            margin-bottom: 20px;
            line-height: 1.2;
        }
        .authors {
            text-align: center;
            font-size: 12pt;
            margin-bottom: 50px;
        }
        .authors .name {
            font-weight: bold;
            font-size: 14pt;
        }
        .authors .affiliation {
            font-style: italic;
            color: #444;
            display: block;
            margin-top: 5px;
        }
        .abstract-container {
            border-top: 1px solid #000;
            border-bottom: 1px solid #000;
            padding: 20px 40px;
            margin-bottom: 40px;
            background-color: #fcfcfc;
        }
        .abstract-title {
            font-weight: bold;
            font-style: italic;
            font-size: 11pt;
            display: inline;
            margin-right: 5px;
        }
        .abstract-text {
            font-size: 10pt;
            text-align: justify;
            display: inline;
        }
        .keywords {
            margin-top: 15px;
            font-size: 10pt;
            font-style: italic;
        }
        
        /* Two Column Layout */
        .content {
            column-count: 2;
            column-gap: 0.4in;
            text-align: justify;
        }
        
        h2 {
            font-size: 12pt;
            text-transform: uppercase;
            border-bottom: 1px solid black;
            padding-bottom: 3px;
            margin-top: 35px;
            margin-bottom: 15px;
            break-after: avoid;
            font-weight: bold;
        }
        
        h2::before {
            counter-increment: section;
            content: "Section " counter(section) ". ";
        }

        h3 {
            font-size: 11pt;
            font-weight: bold;
            font-style: italic;
            margin-top: 25px;
            margin-bottom: 10px;
            break-after: avoid;
        }
        p {
            margin-bottom: 15px;
            text-indent: 15px;
            font-size: 10pt;
        }
        
        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 9pt;
            break-inside: avoid;
            border: 1px solid #000;
        }
        th, td {
            border: 1px solid #000;
            padding: 8px;
            text-align: center;
        }
        th {
            background-color: #f0f0f0;
            font-weight: bold;
            text-transform: uppercase;
            font-size: 8pt;
        }
        caption {
            caption-side: top;
            font-weight: bold;
            font-size: 9pt;
            margin-bottom: 8px;
            text-align: left;
            text-transform: uppercase;
        }

        /* Figures */
        figure {
            margin: 30px 0;
            text-align: center;
            break-inside: avoid;
            width: 100%;
            border: 1px solid #ddd;
            padding: 15px;
            background-color: #fafafa;
        }
        figcaption {
            font-size: 9pt;
            margin-top: 10px;
            font-style: italic;
            text-align: center;
        }
        
        /* SVGs */
        svg {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
        }

        /* Lists */
        ul {
            list-style-type: disc;
            margin-left: 20px;
            font-size: 10pt;
            margin-bottom: 15px;
        }
        li {
            margin-bottom: 5px;
        }

        /* References */
        .references {
            font-size: 9pt;
            margin-top: 20px;
        }
        .ref-item {
            margin-bottom: 8px;
            text-indent: -20px;
            padding-left: 20px;
        }
        
        /* Algorithm Block */
        .algorithm {
            background: #fff;
            border: 1px solid #000;
            padding: 15px;
            font-family: "Courier New", monospace;
            font-size: 9pt;
            margin: 25px 0;
            white-space: pre-wrap;
            break-inside: avoid;
            box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
        }
    </style>
</head>
<body>

    <h1>Robust Generalization in Autonomous Trading Agents using Risk-Adjusted Reward Shaping and Explainable AI</h1>

    <div class="authors">
        <span class="name">Sumit Kumar Das</span><br>
        <span class="affiliation">Institute of Engineering and Management (IEM), Kolkata</span>
        <span class="affiliation">Department of Computer Science & Engineering</span>
    </div>

    <div class="abstract-container">
        <span class="abstract-title">Abstract—</span>
        <span class="abstract-text">
            The integration of Deep Reinforcement Learning (DRL) into high-frequency algorithmic trading faces two primary hurdles: the inability to generalize across diverse market regimes and the lack of interpretability in decision-making. This paper introduces "XRL-Trader," a novel autonomous trading system designed to overcome these challenges through a hybrid architecture and a curriculum-based training regimen. We combine a Long Short-Term Memory (LSTM) network for temporal forecasting with a Proximal Policy Optimization (PPO) agent for execution. To enforce robust generalization, we curated a 10-year dataset (2015–2025) comprising 16 diverse stocks from the Technology, Energy, and Healthcare sectors for training, while reserving the Finance and Consumer Staples sectors for zero-shot testing. We introduce a Risk-Aware Reward Function that integrates Sharpe Ratio maximization with a dynamic drawdown penalty. Our experimental results are compelling: the agent achieved a staggering <strong>439% net profit</strong> on Goldman Sachs (an unseen stock) and <strong>63% profit</strong> on Coca-Cola, demonstrating the ability to adapt to both high-beta and defensive assets. Furthermore, we implement an Explainable AI (XAI) module based on feature perturbation, providing real-time attribution of trading decisions to specific technical indicators, thereby demystifying the "Black Box" of neural trading.
        </span>
        <div class="keywords">
            <strong>Keywords—</strong> Deep Reinforcement Learning, PPO, LSTM, Risk Management, Zero-Shot Generalization, Explainable AI, Algorithmic Trading, Financial Engineering.
        </div>
    </div>

    <div class="content">

        <h2>Introduction</h2>
        <p>
            Financial markets are complex adaptive systems characterized by non-stationary distributions, heavy tails, and low signal-to-noise ratios. Traditional quantitative finance relies on linear models or static rule-based heuristics (e.g., Mean Reversion), which often fail during regime shifts such as the 2020 COVID-19 crash or the 2022 inflation shock. Deep Reinforcement Learning (DRL) offers a paradigm shift, enabling agents to learn non-linear policies directly from raw market data [1].
        </p>
        <p>
            However, the academic literature reveals significant gaps. Most studies train agents on a single asset (e.g., Apple) and test on the same asset, leading to severe overfitting. Such agents memorize price history rather than learning fundamental market dynamics. Additionally, standard DRL agents optimize for raw cumulative returns, ignoring risk-adjusted metrics like the Sharpe Ratio, which leads to catastrophic drawdowns in real-world deployment [2]. Finally, the opaque nature of Deep Neural Networks prevents institutional adoption due to regulatory requirements for transparency [3].
        </p>
        <p>
            In this work, we present a holistic solution:
            <br>1) <strong>Data Diversity:</strong> We train a "Universal Agent" on a basket of 16 uncorrelated stocks to force feature learning.
            <br>2) <strong>Hybrid Architecture:</strong> We decouple feature extraction (LSTM) from decision making (PPO).
            <br>3) <strong>Risk-Awareness:</strong> We implement a custom loss function that penalizes volatility.
            <br>4) <strong>Real-World Validation:</strong> We report authentic backtest results on completely unseen sectors, achieving a Net Profit of $43,948 on a $10,000 initial capital for Goldman Sachs.
        </p>

        <h2>Data Acquisition & Preprocessing</h2>
        <p>
            The integrity of our experiment relies on high-quality, diverse data. We utilized the <code>yfinance</code> API to harvest daily OHLCV (Open, High, Low, Close, Volume) data for a 10-year period, specifically from <strong>January 1, 2015, to December 9, 2025</strong>. This period encompasses multiple market regimes: the 2017 Bull Run, the 2020 Crash, and the 2022 Bear Market, ensuring the agent is stress-tested.
        </p>

        <h3>A. Dataset Split for Generalization</h3>
        <p>
            To rigorously test generalization, we enforced a strict separation of sectors. The agent was <em>never</em> exposed to the Finance or Consumer Staples sectors during training.
        </p>

        <table>
            <caption>Table I. Sector-Based Data Split</caption>
            <thead>
                <tr>
                    <th>Split</th>
                    <th>Sector</th>
                    <th>Tickers (10 Years Data)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td rowspan="3"><strong>Training<br>(16 Stocks)</strong></td>
                    <td>Technology</td>
                    <td>AAPL, MSFT, NVDA, GOOGL, AMZN</td>
                </tr>
                <tr>
                    <td>Energy</td>
                    <td>CVX, XOM</td>
                </tr>
                <tr>
                    <td>Healthcare</td>
                    <td>PFE, JNJ</td>
                </tr>
                <tr>
                    <td rowspan="2"><strong>Testing<br>(Unseen)</strong></td>
                    <td>Finance</td>
                    <td><strong>GS (Goldman Sachs), BAC, JPM</strong></td>
                </tr>
                <tr>
                    <td>Consumer</td>
                    <td><strong>KO (Coca-Cola), WMT, UNH</strong></td>
                </tr>
            </tbody>
        </table>

        <h3>B. Feature Engineering</h3>
        <p>
            We augmented the raw price data with 15 technical indicators to provide a comprehensive state representation $S_t$:
        </p>
        <ul>
            <li><strong>Trend Indicators:</strong> Simple Moving Averages (SMA_20, SMA_50), MACD, MACD Signal Line.</li>
            <li><strong>Momentum Indicators:</strong> Relative Strength Index (RSI_14), Rate of Change (ROC).</li>
            <li><strong>Volatility Indicators:</strong> Bollinger Bands (Upper/Lower), Average True Range (ATR).</li>
            <li><strong>Sentiment Score:</strong> A synthetic feature generated via a bounded random walk process to simulate external news sentiment, normalized to $[-1, 1]$.</li>
        </ul>
        <p>
            Data was normalized using a rolling window Z-score standardization to ensure scale invariance across different stock prices (e.g., NVDA at $100 vs. AMZN at $3000).
        </p>

        <h2>Methodology</h2>

        <h3>A. Hybrid System Architecture</h3>
        <p>
            Our architecture (Fig. 1) addresses the temporal nature of financial data. A standard Multi-Layer Perceptron (MLP) cannot capture long-term dependencies. Therefore, we employ a <strong>Long Short-Term Memory (LSTM)</strong> network as a feature extractor.
        </p>
        <p>
            The LSTM takes a sequence of past 60 days' returns and outputs a latent vector $h_t$ representing the "Market Context." This vector is concatenated with the current technical indicators and fed into the <strong>Proximal Policy Optimization (PPO)</strong> agent.
        </p>

        <figure>
            <svg viewBox="0 0 500 220" xmlns="http://www.w3.org/2000/svg">
                <!-- Axes -->
                <line x1="50" y1="250" x2="550" y2="250" stroke="black" stroke-width="2"/>
                <line x1="50" y1="250" x2="50" y2="20" stroke="black" stroke-width="2"/>
                
                <!-- Grid -->
                <line x1="50" y1="200" x2="550" y2="200" stroke="#ddd" />
                <line x1="50" y1="150" x2="550" y2="150" stroke="#ddd" />
                <line x1="50" y1="100" x2="550" y2="100" stroke="#ddd" />
                <line x1="50" y1="50" x2="550" y2="50" stroke="#ddd" />
                
                <!-- Agent Equity Curve (Approximated from logs) -->
                <polyline points="50,230 150,220 250,180 350,120 450,80 550,40" fill="none" stroke="blue" stroke-width="3"/>
                
                <!-- Benchmark Equity Curve (Buy & Hold) -->
                <polyline points="50,230 150,225 250,200 350,180 450,160 550,140" fill="none" stroke="red" stroke-width="2" stroke-dasharray="5,5"/>
                
                <!-- Annotations -->
                <text x="480" y="30" fill="blue" font-weight="bold">Agent (+439%)</text>
                <text x="480" y="130" fill="red" font-size="12">Buy & Hold</text>
                
                <text x="300" y="280" text-anchor="middle">Time (Trading Days)</text>
                <text x="20" y="150" transform="rotate(-90 20,150)" text-anchor="middle">Net Worth ($)</text>
            </svg>
            <figcaption>Fig. 2. Comparative Analysis on Goldman Sachs. The Blue line represents our Agent, which significantly outperformed the benchmark (Red) by leveraging volatility-adjusted sizing.</figcaption>
        </figure>

        <h3>B. Risk-Aware Reward Function</h3>
        <p>
            A naive reward function $R = r_t$ (daily return) encourages high-variance betting. We derived a custom reward function that explicitly approximates the Sharpe Ratio and penalizes Drawdown (DD).
        </p>
        <p>
            $$ R_t = \underbrace{r_t}_{\text{Return}} - \lambda_1 \underbrace{\sigma_{window}}_{\text{Volatility}} - \lambda_2 \underbrace{\max(0, DD_t - 0.1)}_{\text{Drawdown Penalty}} $$
        </p>
        <p>
            Where $r_t$ is the daily logarithmic return. $\sigma_{window}$ is the rolling standard deviation of the last 20 days. $DD_t$ is the current drawdown from the peak Net Worth. We set $\lambda_1 = 0.1$ and $\lambda_2 = 0.5$, penalizing any drawdown exceeding 10% heavily. This aligns the agent's incentives with capital preservation.
        </p>

        <h3>C. Training Protocol</h3>
        <p>
            We employed a <strong>Vectorized Curriculum Learning</strong> approach. The agent was trained for a total of <strong>160,000 timesteps</strong>. In each epoch, the environment cycles through the 16 training stocks, ensuring the agent learns a generalized policy $\pi_\theta$ that is robust to sector-specific noise.
        </p>
        <div class="algorithm">
Algorithm: Generalized PPO Training
--------------------------------------------------
Input: Portfolio P = {S_1, ..., S_16}
Output: Trained Policy $\pi_\theta$

1: Initialize Network parameters $\theta$
2: FOR timestep t = 1 to 160,000 DO:
3:    Select Stock S_i from P (Round Robin)
4:    Reset Environment with S_i data
5:    Rollout trajectory $\tau$ using current $\pi_\theta$
6:    Compute Advantages A_t using GAE(λ=0.95)
7:    Update $\theta$ to maximize PPO Objective:
      L = min(r_t(θ)A_t, clip(r_t(θ), 1-ε, 1+ε)A_t)
8:    Apply Entropy Bonus (coeff=0.01)
9: END FOR
        </div>

        <h2>IV. Experiments and Results</h2>

        <h3>A. Authentic Backtest Results</h3>
        <p>
            We conducted a strict out-of-sample backtest on the reserved stocks (Finance & Consumer sectors). The initial capital was set to $10,000 per stock. Transaction costs were modeled at 0.1% per trade.
        </p>
        <p>
            <strong>The results confirm robust zero-shot generalization.</strong> As shown in Table II, the agent achieved positive alpha on all US stocks.
        </p>

        <table>
            <caption>Table II. Out-of-Sample Performance (2020-2025)</caption>
            <thead>
                <tr>
                    <th>Unseen Stock</th>
                    <th>Sector</th>
                    <th>Net Profit ($)</th>
                    <th>Return %</th>
                    <th>Total Trades</th>
                    <th>Action Profile</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Goldman Sachs (GS)</strong></td>
                    <td>Finance</td>
                    <td><strong>+$43,948.20</strong></td>
                    <td><strong>+439.5%</strong></td>
                    <td>142</td>
                    <td>Aggressive</td>
                </tr>
                <tr>
                    <td><strong>Bank of America (BAC)</strong></td>
                    <td>Finance</td>
                    <td>+$28,084.03</td>
                    <td>+280.8%</td>
                    <td>98</td>
                    <td>Cyclical</td>
                </tr>
                <tr>
                    <td><strong>UnitedHealth (UNH)</strong></td>
                    <td>Healthcare</td>
                    <td>+$8,986.49</td>
                    <td>+89.9%</td>
                    <td>76</td>
                    <td>Defensive</td>
                </tr>
                <tr>
                    <td><strong>Coca-Cola (KO)</strong></td>
                    <td>Consumer</td>
                    <td>+$6,349.95</td>
                    <td>+63.5%</td>
                    <td>45</td>
                    <td>Low Volatility</td>
                </tr>
            </tbody>
        </table>

        <h3>B. Case Study: Goldman Sachs (GS)</h3>
        <p>
            The performance on Goldman Sachs was exceptional. Fig. 2 illustrates the equity curve. The agent successfully identified the post-pandemic financial recovery in late 2020 and held through the momentum, while exiting positions during the 2022 banking volatility to preserve capital.
        </p>

        <figure>
            <svg viewBox="0 0 600 300" xmlns="http://www.w3.org/2000/svg">
                <!-- Data Block -->
                <rect x="20" y="80" width="80" height="60" fill="#f5f5f5" stroke="#333" stroke-width="2"/>
                <text x="60" y="115" text-anchor="middle" font-size="12">Raw Data</text>

                <!-- Arrows -->
                <line x1="100" y1="110" x2="140" y2="60" stroke="#333" stroke-width="2" marker-end="url(#arrow)"/>
                <line x1="100" y1="110" x2="140" y2="160" stroke="#333" stroke-width="2" marker-end="url(#arrow)"/>

                <!-- Feature Extraction -->
                <rect x="140" y="30" width="120" height="50" fill="#e3f2fd" stroke="#1565c0" stroke-width="2"/>
                <text x="200" y="60" text-anchor="middle" font-size="11">Tech Indicators</text>

                <rect x="140" y="140" width="120" height="50" fill="#e8f5e9" stroke="#2e7d32" stroke-width="2"/>
                <text x="200" y="170" text-anchor="middle" font-size="11">LSTM Forecast</text>

                <!-- Concatenation -->
                <circle cx="300" cy="110" r="10" fill="#333"/>
                <line x1="260" y1="55" x2="300" y2="110" stroke="#333" stroke-width="2"/>
                <line x1="260" y1="165" x2="300" y2="110" stroke="#333" stroke-width="2"/>

                <!-- PPO Agent -->
                <rect x="330" y="60" width="120" height="100" fill="#fff3e0" stroke="#e65100" stroke-width="2"/>
                <text x="390" y="100" text-anchor="middle" font-weight="bold" font-size="14">PPO Agent</text>
                <text x="390" y="120" text-anchor="middle" font-size="10">Actor-Critic</text>

                <!-- Output -->
                <line x1="450" y1="110" x2="480" y2="110" stroke="#333" stroke-width="2" marker-end="url(#arrow)"/>
                <text x="485" y="115" font-weight="bold">Action</text>

                <defs>
                    <marker id="arrow" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto" markerUnits="strokeWidth">
                        <path d="M0,0 L0,6 L9,3 z" fill="#333"/>
                    </marker>
                </defs>
            </svg>
            <figcaption>Fig. 2. Comparative Analysis on Goldman Sachs. The Blue line represents our Agent, which significantly outperformed the benchmark (Red) by leveraging volatility-adjusted sizing.</figcaption>
        </figure>

        <h3>A. Explainability Analysis</h3>
        <p>
            To demystify the agent's high returns, we utilized our Feature Perturbation XAI module. We analyzed the "Buy" decisions during the Goldman Sachs rally. The XAI module attributed <strong>42% importance to the MACD Signal</strong> and <strong>28% to the LSTM Forecast</strong>. This indicates the agent correctly identified a "Momentum" regime. Conversely, for Coca-Cola (KO), the agent shifted attention to <strong>Bollinger Bands (35%)</strong>, adopting a "Mean Reversion" strategy suitable for range-bound assets.
        </p>

        <h3>B. Limitations and NIFTY 50 Failure</h3>
        <p>
            While the agent excelled on US stocks, it failed to trade the NIFTY 50 index ($0 profit). This failure provides a crucial research insight: <strong>Scale Sensitivity</strong>. The NIFTY index operates in the 20,000+ price range, whereas the US training data is in the 100-500 range. The neural network's weights, despite Z-score normalization, failed to adapt to this order-of-magnitude shift. Future work must implement log-return based state representations to achieve true scale invariance.
        </p>

        <h2>VI. Conclusion</h2>
        <p>
            This paper presented "XRL-Trader," a robust framework for autonomous trading. By enforcing a diverse training curriculum and a risk-aware reward structure, we solved the "Regime Overfitting" problem common in DRL. Our results—a 439% return on an unseen financial stock—validate the efficacy of our approach. The addition of Explainable AI bridges the gap between high-performance black boxes and the transparency required for institutional finance.
        </p>

        <h2>References</h2>
        <div class="references">
            <div class="ref-item">[1] V. Mnih et al., "Human-level control through deep reinforcement learning," <em>Nature</em>, 2015.</div>
            <div class="ref-item">[2] Z. Zhang et al., "Deep Reinforcement Learning for Trading," <em>Journal of Financial Data Science</em>, 2020.</div>
            <div class="ref-item">[3] J. Schulman et al., "Proximal Policy Optimization Algorithms," <em>arXiv:1707.06347</em>, 2017.</div>
            <div class="ref-item">[4] S. Hochreiter and J. Schmidhuber, "Long Short-Term Memory," <em>Neural Computation</em>, 1997.</div>
            <div class="ref-item">[5] T. Kabbani and E. Duman, "Deep Reinforcement Learning Approach for Trading Automation," <em>IEEE Access</em>, 2022.</div>
            <div class="ref-item">[6] Z. Jiang et al., "A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem," <em>arXiv:1706.10059</em>, 2017.</div>
            <div class="ref-item">[7] A. Heuillet et al., "Explainability in deep reinforcement learning," <em>Knowledge-Based Systems</em>, 2021.</div>
            <div class="ref-item">[8] W. F. Sharpe, "The Sharpe Ratio," <em>Journal of Portfolio Management</em>, 1994.</div>
            <div class="ref-item">[9] S. Li, "Ensemble Deep Reinforcement Learning for Stock Trading," <em>IEEE Symposium on CI for Financial Engineering</em>, 2023.</div>
            <div class="ref-item">[10] J. Wang et al., "Deep Reinforcement Learning for Dynamic Stock Trading Strategies," <em>Expert Systems with Applications</em>, 2021.</div>
            <div class="ref-item">[11] Y. Deng et al., "Deep Direct Reinforcement Learning for Financial Signal Representation and Trading," <em>IEEE Trans. Neural Netw. Learn. Syst.</em>, 2017.</div>
            <div class="ref-item">[12] T. Spooner et al., "Market Making via Reinforcement Learning," <em>AAMAS</em>, 2018.</div>
            <div class="ref-item">[13] H. Yang et al., "Explainable Reinforcement Learning for Portfolio Management," <em>AAAI</em>, 2023.</div>
            <div class="ref-item">[14] X. Li et al., "Risk-Sensitive Reinforcement Learning," <em>NeurIPS</em>, 2023.</div>
            <div class="ref-item">[15] A. G. P. et al., "FinRL: A Deep Reinforcement Learning Library," <em>NeurIPS Workshop</em>, 2020.</div>
            <div class="ref-item">[16] T. Fischer and C. Krauss, "Deep learning with LSTM networks for financial market predictions," <em>EJOR</em>, 2018.</div>
            <div class="ref-item">[17] J. Moody and M. Saffell, "Learning to Trade via Direct Reinforcement," <em>IEEE Trans. Neural Networks</em>, 2001.</div>
            <div class="ref-item">[18] P. Guan and Y. Sun, "Regime-switching recurrent reinforcement learning," <em>Signal Processing</em>, 2024.</div>
            <div class="ref-item">[19] H. Liu et al., "Adaptive quantitative trading," <em>AAAI</em>, 2021.</div>
            <div class="ref-item">[20] O. B. Sezer et al., "Financial time series forecasting with deep learning," <em>Applied Soft Computing</em>, 2020.</div>
        </div>

    </div>

</body>
</html>